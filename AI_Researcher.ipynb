{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f1ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded configuration from .env file\n",
      "\n",
      "üîë API Key Status:\n",
      "  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "  ‚úÖ Valyu API key loaded: 8kVFqWe6uf...\n",
      "\n",
      "üìÅ Working directory: /Users/navneetmann/Documents/hack/Great_Agent_Hack_2025_EduAI\n",
      "\n",
      "‚úÖ Holistic AI Bedrock helper function loaded\n",
      "\n",
      "‚úÖ All imports successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navneetmann/Documents/hack/Great_Agent_Hack_2025_EduAI/holistic_ai_bedrock.py:17: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  class HolisticAIBedrockChat(BaseChatModel):\n"
     ]
    }
   ],
   "source": [
    "%run holistic_ai_bedrock.py\n",
    "%run load_the_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca68de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from valyu import Valyu\n",
    "from typing import TypedDict, Annotated, List, Dict\n",
    "import operator\n",
    "import yaml\n",
    "from langgraph.graph import StateGraph, END\n",
    "from holistic_ai_bedrock import get_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee65d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state that will be passed between agents\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"State object that flows through the agent graph\"\"\"\n",
    "    keywords: str\n",
    "    context: str\n",
    "    papers: Annotated[List[Dict], operator.add]\n",
    "    main_ideas: Annotated[List[str], operator.add]\n",
    "    new_ideas: List[str]\n",
    "    validated_ideas: List[Dict]\n",
    "    current_step: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917650bc",
   "metadata": {},
   "source": [
    "### Multi-Agent Research Paper Innovation System using LangGraph\n",
    "\n",
    "This system uses 4 agents to:\n",
    "1. Scrape research papers based on keywords (using Valyu web search)\n",
    "2. Summarize main ideas from papers\n",
    "3. Combine ideas to generate novel concepts\n",
    "4. Check if generated ideas are actually new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a940f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valyu import SearchResponse\n",
    "\n",
    "class ResearchInnovationSystem:\n",
    "    \"\"\"Multi-agent system for research paper analysis and idea generation\"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, max_papers: int = 5, chat_model_name: str = \"claude-3-5-sonnet\",\n",
    "                 yaml_file_path: str=r\"prompts.yaml\", RELEVANCE_SCORE_THRES: int=0.5):\n",
    "        \n",
    "        self.llm = get_chat_model(chat_model_name)\n",
    "        self.valyu_api_key = os.getenv('VALYU_API_KEY')\n",
    "        self.valyu = Valyu(self.valyu_api_key)\n",
    "        self.max_papers = max_papers\n",
    "        self.RELEVANCE_SCORE_THRES = RELEVANCE_SCORE_THRES\n",
    "\n",
    "        # setup graph and load config\n",
    "        self.config = self._load_prompt_config(yaml_file_path)\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "\n",
    "    \n",
    "    def _load_prompt_config(self, yaml_file_path):\n",
    "        \"\"\"Loads the prompt templates from a YAML file.\"\"\"\n",
    "\n",
    "        if not os.path.exists(yaml_file_path):\n",
    "            raise FileNotFoundError(f\"Config file not found: {yaml_file_path}\")\n",
    "        \n",
    "        with open(yaml_file_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            \n",
    "        return config\n",
    "    \n",
    "\n",
    "    \n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"Build the LangGraph workflow\"\"\"\n",
    "\n",
    "        workflow = StateGraph(ResearchState)\n",
    "        \n",
    "        # Add nodes for each agent\n",
    "        workflow.add_node(\"scraper\", self.scraper_agent)\n",
    "        workflow.add_node(\"summarizer\", self.summarizer_agent)\n",
    "        workflow.add_node(\"novel_idea_generator\", self.novel_idea_generator_agent)\n",
    "        workflow.add_node(\"validator\", self.validator_agent)\n",
    "        \n",
    "        # add a terminal node when scraper returns no valid papers\n",
    "        workflow.add_node(\"no_results\", self.no_results_agent)\n",
    "\n",
    "        # Define the routing logic after the scraper\n",
    "        def route_after_scraper(state: ResearchState) -> str:\n",
    "            \"\"\"Determines the next step after scraping.\"\"\"\n",
    "            if state.get(\"papers\"):\n",
    "                return \"summarizer\"\n",
    "            return \"no_results\"\n",
    "\n",
    "        # Define the flow\n",
    "        workflow.set_entry_point(\"scraper\")\n",
    "\n",
    "        # Conditional edges from the scraper node\n",
    "        workflow.add_conditional_edges(\n",
    "            \"scraper\",\n",
    "            route_after_scraper,\n",
    "            # Maps the returned string from the function to the next node name\n",
    "            {\"summarizer\": \"summarizer\", \"no_results\": \"no_results\"}\n",
    "        )\n",
    "\n",
    "        # Unconditional edges for the main path\n",
    "        workflow.add_edge(\"summarizer\", \"novel_idea_generator\")\n",
    "        workflow.add_edge(\"novel_idea_generator\", \"validator\")\n",
    "\n",
    "        # Terminal nodes\n",
    "        workflow.add_edge(\"validator\", END)\n",
    "        workflow.add_edge(\"no_results\", END)\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "\n",
    "\n",
    "    def scraper_agent(self, state: ResearchState) -> ResearchState:\n",
    "        \"\"\"\n",
    "        Agent 1: Scrape research papers using Valyu web search API\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\nüîç SCRAPER AGENT: Searching for papers...\")\n",
    "        print(f\"Keywords: {state['keywords']}\")\n",
    "        print(f\"Context: {state['context']}\")\n",
    "        \n",
    "        # Use Valyu API to search for research papers\n",
    "        try:\n",
    "            # https://docs.valyu.ai/api-reference/endpoint/deepsearch#body-query\n",
    "            search_results: SearchResponse = self.valyu.search(\n",
    "                    query=f\"{state['context']} with keywords {{state['keywords']}}\",\n",
    "                    # category={state['keywords']}, # adding this often gives no results so have commented it out\n",
    "                    relevance_threshold=self.RELEVANCE_SCORE_THRES,\n",
    "                    # is_tool_call=True,\n",
    "                    start_date=\"2024-01-01\", # Recent research only\n",
    "                    response_length=\"max\",\n",
    "                    max_num_results=self.max_papers,\n",
    "                )\n",
    "            \n",
    "            # print(search_results)\n",
    "\n",
    "            # Parse the results\n",
    "            papers: List[Dict] = []\n",
    "            # if you get failures, check if credits have expired!\n",
    "            if search_results.success:\n",
    "                for _, result in enumerate(search_results.results):\n",
    "                    paper:Dict = {\n",
    "                        \"title\": result.title,\n",
    "                        \"url\": result.url,\n",
    "                        \"content\": result.content,\n",
    "                        \"description\": result.description,\n",
    "                        \"source\": result.source,\n",
    "                        \"relevance_score\": result.relevance_score\n",
    "                    }\n",
    "                    papers.append(paper)\n",
    "                    print(f\"‚úì Found: {paper['title'][:20]}...\")\n",
    "\n",
    "\n",
    "            print(f\"\\nüìö Scraped {len(papers)} papers\")\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"‚ö†Ô∏è  Error during search: {str(e)}\")            \n",
    "            papers = []\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"papers\": papers,\n",
    "            \"current_step\": \"scraper_complete\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    def summarizer_agent(self, state: ResearchState) -> ResearchState:\n",
    "        \"\"\"\n",
    "        Agent 2: Summarize main interesting ideas from each paper\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\nüìù SUMMARIZER AGENT: Extracting main ideas ...\")\n",
    "        \n",
    "        main_ideas = []\n",
    "        for i, paper in enumerate(state['papers'], 1):\n",
    "\n",
    "            print(f\"\\n Analyzing paper {i}/{len(state['papers'])}: {paper['title'][:60]}...\")\n",
    "            \n",
    "            template_string = self.config['summarizer_prompt']\n",
    "            prompt = template_string.format(\n",
    "                                paper_title=paper['title'],\n",
    "                                paper_content=paper['content'],\n",
    "                                paper_description=paper['description']\n",
    "                            )\n",
    "            response = self.llm.invoke(prompt)            \n",
    "            main_ideas.append(response.content)\n",
    "\n",
    "        print(f\"\\nüí° Main Ideas extracted: \\n{main_ideas}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"main_ideas\": main_ideas,\n",
    "            \"current_step\": \"summarizer_complete\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    def novel_idea_generator_agent(self, state: ResearchState) -> ResearchState:\n",
    "        \"\"\"\n",
    "        Agent 3: Combine ideas to generate novel research directions\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\nüî¨ NOVEL IDEA GENERATOR AGENT: Generating novel ideas...\")\n",
    "        \n",
    "        # Prepare ideas for combination\n",
    "        ideas_text = state['main_ideas']\n",
    "        user_context = state['context']\n",
    "\n",
    "        template_string = self.config['novel_idea_generator_prompt']\n",
    "        prompt = template_string.format(\n",
    "                            context=user_context,\n",
    "                            ideas_text=ideas_text\n",
    "                        )\n",
    "        \n",
    "        response = self.llm.invoke(prompt)\n",
    "        new_ideas = response.content\n",
    "\n",
    "        print(f\"\\nüí° Novel Ideas: \\n{new_ideas}\")\n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            \"new_ideas\": new_ideas,\n",
    "            \"current_step\": \"novel_idea_generation_complete\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    def validator_agent(self, state: ResearchState) -> ResearchState:\n",
    "        \"\"\"\n",
    "        Agent 4: Validate if the generated ideas are actually novel\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\n‚úÖ VALIDATOR AGENT: Validating novelty ...\")\n",
    "        \n",
    "        candidate_new_ideas = state['main_ideas']\n",
    "\n",
    "        template_string = self.config['validator_prompt']\n",
    "        prompt = template_string.format(\n",
    "                            new_ideas=candidate_new_ideas,\n",
    "                        )\n",
    "        response = self.llm.invoke(prompt)\n",
    "            \n",
    "        validated_ideas = response.content\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"validated_ideas\": validated_ideas,\n",
    "            \"current_step\": \"validator_complete\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    def no_results_agent(self, state: ResearchState) -> ResearchState:\n",
    "        \"\"\"Terminal node when scraper finds no valid papers\"\"\"\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"validated_ideas\": \"No relevant papers found for the given keywords/context. Try with broader query or keywords.\",\n",
    "            \"current_step\": \"no_results\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    def run(self, keywords: List[str], context: str = \"\") -> Dict:\n",
    "        \"\"\"\n",
    "        Execute the complete research innovation pipeline\n",
    "        \n",
    "        Args:\n",
    "            keywords: Search keywords for papers (for e.g. ['graph', 'neural networks', 'transformers'])\n",
    "            context: Additional context about research interests\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with validated novel ideas\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"üöÄ RESEARCH INNOVATION SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        \n",
    "        initial_state = {\n",
    "            \"keywords\": \" | \".join(keywords),\n",
    "            \"context\": context or \"General research exploration\",\n",
    "            \"papers\": [],\n",
    "            \"main_ideas\": [],\n",
    "            \"new_ideas\": [],\n",
    "            \"validated_ideas\": [],\n",
    "            \"current_step\": \"initialized\"\n",
    "        }\n",
    "        \n",
    "        # Run the graph\n",
    "        final_state = self.graph.invoke(initial_state)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"main_ideas\": final_state['main_ideas'],\n",
    "            \"novel_ideas\": (final_state['new_ideas']),\n",
    "            \"validated_ideas\": final_state['validated_ideas']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bbd113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ RESEARCH INNOVATION SYSTEM\n",
      "================================================================================\n",
      "\n",
      "üîç SCRAPER AGENT: Searching for papers...\n",
      "Keywords: machine learning | quantitative finance | low latency\n",
      "Context: I need papers related to Algorithmic trading and portfolio optimization\n",
      "‚úì Found: Advancing Investment...\n",
      "‚úì Found: Large Language Model...\n",
      "‚úì Found: The Portfolio Tradin...\n",
      "‚úì Found: Enhancing portfolio ...\n",
      "‚úì Found: Enhancing literature...\n",
      "\n",
      "üìö Scraped 5 papers\n",
      "\n",
      "üìù SUMMARIZER AGENT: Extracting main ideas ...\n",
      "\n",
      " Analyzing paper 1/5: Advancing Investment Frontiers: Industry-grade Deep Reinforc...\n",
      "\n",
      " Analyzing paper 2/5: Large Language Models in equity markets: applications, techn...\n",
      "\n",
      " Analyzing paper 3/5: The Portfolio Trading Algo: Part 1 | by Daniel Aisen | Proof...\n",
      "\n",
      " Analyzing paper 4/5: Enhancing portfolio management using artificial intelligence...\n",
      "\n",
      " Analyzing paper 5/5: Enhancing literature review with LLM and NLP methods. Algori...\n",
      "\n",
      "üí° Main Ideas extracted: \n",
      "['Here are the 3-4 most innovative and interesting ideas from this research paper:\\n\\n1. Novel Integration of Sim-to-Real Methods in Finance:\\nThe paper introduces a groundbreaking application of simulation-to-real (sim-to-real) transfer methodologies from robotics and mathematical physics to financial portfolio optimization. This interdisciplinary approach helps bridge the \"reality gap\" between simulated models and real-world market conditions, potentially improving the robustness of AI trading systems.\\n\\n2. Three-Pillar Framework for Financial RL:\\nThe researchers develop a comprehensive framework for implementing Reinforcement Learning in finance, built on three key principles:\\n- Realistic reward shaping & environmental modeling\\n- Robust risk analysis & statistical stress testing \\n- Strategic resilience & fault tolerance-aware engineering\\nThis structured approach addresses the unique challenges of financial markets while incorporating lessons from high-risk robotics applications.\\n\\n3. Human-in-the-Loop Necessity:\\nThe paper makes a compelling argument against fully autonomous AI trading systems, instead advocating for a \"human-in-the-loop\" approach that combines algorithmic efficiency with human oversight. This perspective acknowledges the complexity of financial markets and the importance of human judgment in risk management and regulatory compliance.\\n\\n4. Parallel Evolution Analysis:\\nThe researchers draw interesting parallels between the evolution of recommendation systems in technology and portfolio optimization in finance, highlighting how both fields face similar challenges (sparse rewards, cold start problems) and suggesting that successful RL applications in tech could inform financial innovation.\\n\\nThese ideas represent significant contributions to the field by offering practical frameworks for implementing AI in finance while maintaining necessary safeguards and controls.', \"Here are the most innovative and interesting ideas from the research paper:\\n\\n1. Multi-Agent Trading Systems with Memory Hierarchies\\n- The development of TradingGPT introduces a novel framework using multiple AI agents with layered memories and distinct characters, mimicking human cognitive processes in trading decisions. This represents a more sophisticated approach to automated trading that better reflects human decision-making patterns.\\n\\n2. Counter-Intuitive Performance of Simpler Models\\n- Research revealed that less sophisticated LLMs sometimes outperform more complex models in trading decisions, particularly in crypto markets. This challenges the common assumption that bigger, more complex models are always better, suggesting efficiency and simplicity might be more valuable in certain trading contexts.\\n\\n3. Hybrid Data Integration Systems\\n- CryptoTrade's approach of combining on-chain and off-chain data for cryptocurrency trading demonstrates how LLMs can bridge traditional and emerging market data sources, creating more comprehensive trading analysis systems.\\n\\n4. Continuous Market Adaptation Framework\\n- The introduction of Reinforcement Learning from Market Feedback (RLMF) represents a significant advancement in creating trading systems that can continuously learn and adapt to changing market conditions, moving beyond static trading strategies.\\n\\n5. Sentiment-Driven Trading Enhancement\\n- The FinLlama framework shows how incorporating sentiment analysis into algorithmic trading can improve portfolio returns even in volatile markets, demonstrating the value of combining quantitative and qualitative data in trading decisions.\", 'Here are the 4 most innovative and interesting ideas from the paper:\\n\\n1. Novel Approach to Portfolio Trading Algorithm:\\nThe paper presents a unique three-component architecture combining user interface, basket manager trading application, and basket optimization model - designed to maintain sophisticated balance between multiple buy/sell orders while minimizing market risk.\\n\\n2. Flexible Constraint System:\\nThe algorithm introduces an innovative \"discretion\" feature that allows traders to set both short-term and long-term balance tolerances, enabling dynamic trading paths while still meeting final portfolio objectives (e.g., allowing 10% imbalance during trading but requiring 1% balance at completion).\\n\\n3. Adaptive Architecture:\\nThe system leverages existing single-stock algorithms while adding a new layer of portfolio-level optimization, creating a scalable framework that can handle increasingly complex trading scenarios without rebuilding core components.\\n\\n4. Future Innovation Potential:\\nThe paper outlines several groundbreaking potential upgrades, including:\\n- Auto-hedging capabilities using ETFs\\n- \"Basket of baskets\" functionality for handling overlapping orders\\n- Joint market impact modeling across multiple securities\\n\\nThese ideas represent significant innovations in institutional trading technology, particularly in balancing complexity with usability and scalability.', 'Based on the research paper, here are the 3 most innovative and interesting ideas:\\n\\n1. AI Integration in Portfolio Management:\\nThe paper highlights how AI is revolutionizing traditional portfolio management through multiple channels - from machine learning for price prediction to reinforcement learning for dynamic optimization, and text mining for market sentiment analysis. This represents a significant shift from traditional Markowitz mean-variance models.\\n\\n2. Black Box Challenge & Explainability:\\nA novel challenge identified is the tension between AI\\'s superior performance and its \"black box\" nature in portfolio management. The paper emphasizes the emerging importance of eXplainable AI (XAI) in gaining stakeholder trust, introducing a new dimension to portfolio management that wasn\\'t relevant in traditional approaches.\\n\\n3. Multi-Dimensional AI Applications:\\nThe research reveals how AI enhances portfolio management across multiple dimensions simultaneously:\\n- Processing vast amounts of data\\n- Improving risk estimates\\n- Automating operational efficiency\\n- Detecting latent factors for better diversification\\n- Creating portfolios that can mimic indices with fewer assets\\n\\nThese ideas are particularly innovative as they represent a fundamental shift in how portfolio management is approached, moving from purely mathematical models to more dynamic, data-driven, and adaptive systems.', \"Here are the most innovative and interesting ideas from this research paper:\\n\\n1. Novel Methodology Integration:\\nThe paper combines advanced NLP techniques (BERT, UMAP, HDBSCAN) with LLM validation (ChatGPT) to create a hybrid approach for literature review automation - representing a new framework for systematic research analysis.\\n\\n2. Automated Research Pattern Detection:\\nThe researchers developed an automated system that can identify and analyze research trends, methodological patterns, and comparative results across large academic databases (136M+ papers), offering a scalable approach to literature review that wasn't previously possible.\\n\\n3. Multi-Dimensional Analysis Framework:\\nThe study introduced a comprehensive analytical framework that simultaneously examines multiple dimensions of research papers (time horizons, asset classes, methodologies) while tracking their evolution over time, revealing hidden patterns in academic focus areas.\\n\\n4. Time-Based Trend Identification:\\nThe research revealed interesting temporal patterns in financial research, such as the emergence of cryptocurrency studies and spikes in commodity research during specific market events (2014-2016 oil crisis), demonstrating how external events influence academic focus.\\n\\nThese findings suggest a significant advancement in how literature reviews can be conducted using AI/ML tools while providing valuable insights into the evolution of algorithmic trading research.\"]\n",
      "\n",
      "üî¨ NOVEL IDEA GENERATOR AGENT: Generating novel ideas...\n",
      "\n",
      "üí° Novel Ideas: \n",
      "{\n",
      "  \"research_ideas\": [\n",
      "    \"Develop a 'Multi-Memory Portfolio Optimizer' that combines the multi-agent trading system's memory hierarchies with traditional portfolio optimization, creating different memory layers for various time horizons (short-term tactical, medium-term strategic, long-term fundamental) to better mirror institutional investment processes\",\n",
      "    \n",
      "    \"Create an 'Adaptive Sim-to-Real Portfolio Framework' that uses the three-pillar RL framework alongside the flexible constraint system, allowing portfolios to gradually transition from simulation to real trading while maintaining dynamic risk boundaries and learning from market feedback\",\n",
      "    \n",
      "    \"Design a 'Hybrid XAI Trading System' that combines sentiment analysis from FinLlama with explainable AI techniques, providing human-readable justifications for trading decisions while incorporating both quantitative and qualitative market data\",\n",
      "    \n",
      "    \"Implement an 'Auto-Hedging Network' that uses the basket optimization model combined with NLP-driven market analysis to automatically identify and execute hedging opportunities across multiple asset classes, optimizing for both return and risk metrics\",\n",
      "    \n",
      "    \"Develop a 'Continuous Learning Portfolio Architecture' that merges the RLMF framework with automated research pattern detection, allowing trading strategies to evolve based on both market feedback and real-time academic research findings\",\n",
      "    \n",
      "    \"Create a 'Multi-Dimensional Risk Optimization System' that combines the black box challenge solutions with the three-component trading architecture, providing transparent risk management while maintaining sophisticated trading capabilities across multiple assets\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "‚úÖ VALIDATOR AGENT: Validating novelty ...\n",
      "I'll analyze the novelty of these ideas and present only those that appear to be genuinely innovative based on the criteria provided.\n",
      "\n",
      "VALIDATED NOVEL IDEAS:\n",
      "\n",
      "1. Sim-to-Real Transfer in Finance\n",
      "- Truly novel application of robotics methodology to finance\n",
      "- Non-obvious combination of disparate fields\n",
      "- Addresses a genuine gap in financial modeling\n",
      "- Unique approach to bridging simulation-reality gap in trading\n",
      "\n",
      "2. Multi-Agent Trading with Memory Hierarchies (TradingGPT)\n",
      "- Novel architecture incorporating multiple specialized agents\n",
      "- Unique approach to mimicking human cognitive trading patterns\n",
      "- Demonstrates innovative use of LLMs in trading context\n",
      "\n",
      "3. Flexible Portfolio Constraint System\n",
      "- Novel \"discretion\" feature allowing dynamic trading paths\n",
      "- Innovative balance between short and long-term constraints\n",
      "- Practical advancement in institutional trading\n",
      "\n",
      "4. Hybrid Data Integration for Crypto Trading\n",
      "- Original combination of on-chain and off-chain data\n",
      "- Non-obvious application of traditional methods to new asset class\n",
      "- Addresses unique challenges in crypto market analysis\n",
      "\n",
      "IDEAS REJECTED AS NOT SUFFICIENTLY NOVEL:\n",
      "- General AI integration in portfolio management (already widely documented)\n",
      "- Black box challenges & explainability (common theme in AI literature)\n",
      "- Basic sentiment analysis for trading (well-established concept)\n",
      "- Standard research pattern detection (existing methodology)\n",
      "\n",
      "Note: The validated ideas represent genuine innovations that:\n",
      "- Combine existing concepts in non-obvious ways\n",
      "- Address specific gaps in current knowledge\n",
      "- Offer substantial improvements over existing methods\n",
      "- Present truly new approaches to known problems\n"
     ]
    }
   ],
   "source": [
    "# Initialize the system\n",
    "# make sure your .env has keys \n",
    "ris = ResearchInnovationSystem(\n",
    "    chat_model_name=\"claude-3-5-sonnet\",\n",
    "    max_papers=5,\n",
    "    yaml_file_path=\"prompts.yaml\",\n",
    "    RELEVANCE_SCORE_THRES=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# When button clicked on UI it will call this func using the values from UI!\n",
    "# At present, have hard coded the values ()\n",
    "results = ris.run(\n",
    "    keywords=[\"machine learning\", \"quantitative finance\", \"low latency\"],  # list of keywords\n",
    "    context=\"I need papers related to Algorithmic trading and portfolio optimization\"  # user query \n",
    ")\n",
    "\n",
    "# Access results\n",
    "print(results['validated_ideas'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
